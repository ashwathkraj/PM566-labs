mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
filter(token == "pain" & token == "pulmonary") %>%
count(token, sort = TRUE) %>%
top_n(5,n)
mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
filter(token == "pain" | token == "pulmonary") %>%
count(token, sort = TRUE) %>%
top_n(5,n)
mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
filter(token == "pain" | token == "pulmonary") %>%
count(token, sort = TRUE) %>%
top_n(1,n)
mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
filter(token == "pain" | token == "pulmonary") %>%
count(token, sort = TRUE) %>%
top_n(5,n)
mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
filter(token == "pain") %>%
count(token, sort = TRUE) %>%
top_n(5,n)
mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
count(token, sort = TRUE) %>%
top_n(5,n)
mt_samples %>%
unnest_tokens(token, transcription) %>%
anti_join(stop_words, by = c("token" = "word"))%>%
group_by(description) %>%
filter(token == "sleep") %>%
count(token, sort = TRUE) %>%
top_n(5,n)
knitr::opts_chunk$set(include  = TRUE)
install.packages("rvest")
knitr::opts_chunk$set(include  = FALSE)
install.packages("httr")
install.packages("xml2")
install.packages("stringr")
install.packages("rvest")
knitr::opts_chunk$set(include  = TRUE)
library("httr")
library("xml2")
library("stringr")
library("rvest")
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")
# Finding the counts
counts <- xml2::xml_find_first(website, "[XPath]")
# Turning it into text
counts <- as.character(counts)
# Extracting the data using regex
stringr::str_extract(counts, "[REGEX FOR NUMBERS WITH COMMAS/DOTS]")
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")
website
https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2
# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[1]/span")
coutns
counts
website
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")
# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[1]/span")
# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/span")
counts
# Turning it into text
counts <- as.character(counts)
# Extracting the data using regex
stringr::str_extract(counts, "[0-9,]+")
query_ids <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
query = list(db= pubmed,
term= covid19 hawaii,
query_ids <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
query = list(db= "pubmed",
term= 'covid19 hawaii',
retmax= '1000')
)
query_ids
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
ids
# Turn the result into a character vector
ids <- as.character(ids)
ids
cat(ids)
# Find all the ids
ids <- stringr::str_extract_all(ids, "[0-9,]+")[[1]]
ids
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
# Find all the ids
ids <- stringr::str_extract_all(ids, "<Id>[0-9,]+")[[1]]
ids
# Find all the ids
ids <- stringr::str_extract_all(ids, "!<Id>[0-9,]+!</Id>")[[1]]
ids
# Find all the ids
ids <- stringr::str_extract_all(ids, "<Id>[0-9,]+</Id>")[[1]]
ids
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
# Turn the result into a character vector
ids <- as.character(ids)
# Find all the ids
ids <- stringr::str_extract_all(ids, "<Id>[0-9,]+</Id>")[[1]]
ids
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "[^[0-9,]+")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "[^0-9,+")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "[^0-9")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "[^0-9]")
ids
# Extracting the content of the response of GET
ids2 <- httr::content(query_ids)
ids2 <- id
ids2 <- ids
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
# Turn the result into a character vector
ids <- as.character(ids)
cat(ids)
# Find all the ids
ids <- stringr::str_extract_all(ids, "<Id>[0-9,]+</Id>")[[1]]
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
# Turn the result into a character vector
ids <- as.character(ids)
# Find all the ids
ids <- stringr::str_extract_all(ids, "<Id>[0-9,]+</Id>")[[1]]
stringr::str_remove_all(ids, "<ID>")
stringr::str_remove_all(ids, "<ID>")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
#ids <- stringr::str_remove_all(ids, "[^0-9]")
ids <- stringr::str_remove_all(ids, "[<ID>]")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
#ids <- stringr::str_remove_all(ids, "[^0-9]")
ids <- stringr::str_remove_all(ids, "[<Id>]")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
#ids <- stringr::str_remove_all(ids, "[^0-9]")
ids <- stringr::str_remove_all(ids, "[</Id>]")
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
#ids <- stringr::str_remove_all(ids, "[^0-9]")
#ids <- stringr::str_remove_all(ids, "[</Id>]")
ids <- stringr::str_remove_all(ids, "<Id>|</Id>")
paste(ids, collapse=",")
ids <- paste(ids, collapse=",")
publications <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
query = list(
db = "pubmed",
id = ids,
retmax = 1000,
rettype = "abstract"
)
)
publications
# Turning the output into character vector
publications <- httr::content(publications)
publications_txt <- as.character(publications)
publications_txt
str_extract_all(
publications_txt,
"University of | Institute of"
)
institution <- str_extract_all(
publications_txt,
"University of\\s[[:alpha:]]| | Institute of"
)
institution
institution <- str_extract_all(
publications_txt,
"University of\\s[[:alpha:]]+ | Institute of"
)
)
institution
institution <- str_extract_all(
publications_txt,
"University of\\s[[:alpha:]]+ | [[:alpha:]]+\sInstitute of\s[[:alpha:]+"
institution <- str_extract_all(
publications_txt,
"University of\\s[[:alpha:]]+ | [[:alpha:]]+\\sInstitute of\\s[[:alpha:]+"
)
institution <- str_extract_all(
publications_txt,
"University of\\s[[:alpha:]]+ | [[:alpha:]]+\\sInstitute of\\s[[:alpha:]]+"
)
institution
institution <- str_extract_all(
publications_txt,
"University of\\s[[:alpha:]]+|[[:alpha:]]+\\sInstitute of\\s[[:alpha:]]+"
)
institution
institution <- unlist(institution)
institution
institution
table(institution)
schools_and_deps <- str_extract_all(
publications_txt,
"School of\\s[[:alpha:]]+|Department of\\s[[:alpha:]]+"
)
table(schools_and_deps)
publicaitons
publications
pub_char_list <- xml2::xml_children(publications)
pub_char_list
pub_char_list <- sapply(pub_char_list, as.character)
pub_char_list <- sapply(pub_char_list, as.character)
pub_char_list <- sapply(pub_char_list, as.character)
pub_char_list <- sapply(pub_char_list, as.character)
pub_char_list
pub_char_list
abstracts <- str_extract(pub_char_list, "<Abstract>[[:alpha:]]+</Abstract>")
abstract
abstracts
abstracts <- str_extract(pub_char_list, "<Abstract>[[:alnum: ]]+</Abstract>")
abstracts
abstracts <- str_extract(pub_char_list, "<Abstract>([[:alnum: ]])+</Abstract>")
abstracts
abstracts <- str_extract(pub_char_list, "<Abstract>([[:alnum: ]])+</Abstract>")
abstract
abstracts
abstracts <- str_extract(pub_char_list[1], "<Abstract>.+")
abstracts
abstracts <- str_extract(pub_char_list[1], "<Abstract>.+")
abstracts
abstracts <- str_extract(pub_char_list[1], "<Abstract>\\n.+")
abstracts
abstracts <- str_extract(pub_char_list[1], "<Abstract>\\n+.+")
abstracts
abstracts <- str_extract(pub_char_list[1], "<Abstract>[\\n.]+")
abstracts
abstracts <- str_extract(pub_char_list[1], "<Abstract>(\\n|.)+</Abstract>")
abstracts
abstracts <- str_remove_all(abstracts, "<.>")
abstracts
abstracts <- str_remove_all(abstracts, "<.>")
abstracts
abstracts <- str_remove_all(abstracts, "<(.)>")
abstracts
abstracts <- str_remove_all(abstracts, "<[.]+>")
abstracts <- str_remove_all(abstracts, "<[[:alpha:]]+>")
abstracts
abstracts <- str_remove_all(abstracts, "<[[:alpha:]]>+")
abstracts
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]]+>")
abstracts
str_remove_all(abstracts, "\n")
abstracts <- str_remove_all(abstracts, "\n\s")
str_remove_all(abstracts, "\n\s")
str_remove_all(abstracts, "\n|\s")
str_remove_all(abstracts, "\n|\\s")
str_remove_all(abstracts, "\n")
str_replace_all(abstracts, "\\s+", " ")
table(is.na(abstracts))
table((abstracts))
abstracts <- str_extract(pub_char_list, "<Abstract>(\\n|.)+</Abstract>")
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]]+>")
abstracts <- str_replace_all(abstracts, "\\s+", " ")
table(is.na(abstracts))
table((abstracts))
titles <- str_extract(pub_char_list, "<ArticleTitle>(\\n|.)+</ArticleTitle>")
titles <- str_remove_all(titles, "</?[[:alnum:]]+>")
titles <- str_replace_all(titles, "\\s+", " ")
titles
data.frame(
title = titles,
abstract = abstracts
)
database <- data.frame(
title = titles,
abstract = abstracts
)
database
View(database)
knitr::kable(database)
database <- data.frame(
pubmed_id = ids,
title = titles,
abstract = abstracts
)
View(database)
database <- data.frame(
pubmed_id = ids2,
title = titles,
abstract = abstracts
)
View(database)
# Benchmarking
microbenchmark::microbenchmark(
fun1(),
fun1alt()
)
install.packages("microbenchmark")
install.packages("microbenchmark")
install.packages("matrix")
library(Matrix)
install.packages("microbenchmark")
install.packages("Matrix")
library(microbenchmark)
library(Matrix)
install.packages("Matrix")
fun1 <- function(n = 100, k = 4, lambda = 4) {
x <- NULL
for (i in 1:n)
x <- rbind(x, rpois(k, lambda))
x
}
fun1alt <- function(n = 100, k = 4, lambda = 4) {
matrix(rpois(n*k, lambda = lambda), ncol = k)
}
# Benchmarking
microbenchmark::microbenchmark(
fun1(),
fun1alt()
)
# Benchmarking
microbenchmark::microbenchmark(
fun1(),
fun1alt(), unit = "relative"
)
# Data Generating Process (10 x 10,000 matrix)
set.seed(1234)
x <- matrix(rnorm(1e4), nrow=10)
# Find each column's max value
fun2 <- function(x) {
apply(x, 2, max)
}
fun2alt <- function(x) {
# YOUR CODE HERE
max.col(t(x))
}
# Benchmarking
microbenchmark::microbenchmark(
fun2(),
fun2alt()
)
# YOUR CODE HERE
max.col(t(x))
# Benchmarking
microbenchmark::microbenchmark(
fun2(),
fun2alt()
)
# Data Generating Process (10 x 10,000 matrix)
set.seed(1234)
x <- matrix(rnorm(1e4), nrow=10)
# Find each column's max value
fun2 <- function(x) {
apply(x, 2, max)
}
fun2alt <- function(x) {
# YOUR CODE HERE
max.col(t(x))
}
# Benchmarking
microbenchmark::microbenchmark(
fun2(x),
fun2alt(x)
)
# Benchmarking
microbenchmark::microbenchmark(
fun2(x),
fun2alt(x), unit = "relative"
)
# YOUR CODE HERE
#max.col(t(x))
x[cbind(
max.col(t(x)),
1:ncol(x)
)]
# Benchmarking
microbenchmark::microbenchmark(
fun2(x),
fun2alt(x), unit = "relative"
)
my_boot <- function(dat, stat, R, ncpus = 1L) {
# Getting the random indices
n <- nrow(dat)
idx <- matrix(sample.int(n, n*R, TRUE), nrow=n, ncol=R)
# Making the cluster using `ncpus`
# STEP 1: GOES HERE
cl <- makePSOCKcluster(ncpus)
# STEP 2: GOES HERE
parallel::clusterExport(cl, varlist = c("idx", "dat"), envir = environment())
# STEP 3: THIS FUNCTION NEEDS TO BE REPLACES WITH parLapply
ans <- parLapply(cl, seq_len(R), function(i) {
stat(dat[idx[,i], , drop=FALSE])
})
# Coercing the list into a matrix
ans <- do.call(rbind, ans)
# STEP 4: stop the cluster
stopCluster(cl)
ans
}
parallel
#install.packages("microbenchmark")
#install.packages("Matrix")
install.packages("parallel")
install.packages("parallel")
library(parallel)
my_boot <- function(dat, stat, R, ncpus = 1L) {
# Getting the random indices
n <- nrow(dat)
idx <- matrix(sample.int(n, n*R, TRUE), nrow=n, ncol=R)
# Making the cluster using `ncpus`
# STEP 1: GOES HERE
cl <- makePSOCKcluster(ncpus)
# STEP 2: GOES HERE
parallel::clusterExport(cl, varlist = c("idx", "dat", "stat"), envir = environment())
# STEP 3: THIS FUNCTION NEEDS TO BE REPLACES WITH parLapply
ans <- parLapply(cl, seq_len(R), function(i) {
stat(dat[idx[,i], , drop=FALSE])
})
# Coercing the list into a matrix
ans <- do.call(rbind, ans)
# STEP 4: stop the cluster
stopCluster(cl)
ans
}
# Bootstrap of an OLS
my_stat <- function(d) coef(lm(y ~ x, data=d))
# DATA SIM
set.seed(1)
n <- 500; R <- 1e4
x <- cbind(rnorm(n)); y <- x*5 + rnorm(n)
# Checking if we get something similar as lm
ans0 <- confint(lm(y~x))
ans1 <- my_boot(dat = data.frame(x, y), my_stat, R = R, ncpus = 2L)
# You should get something like this
t(apply(ans1, 2, quantile, c(.025,.975)))
##                   2.5%      97.5%
## (Intercept) -0.1372435 0.05074397
## x            4.8680977 5.04539763
ans0
##                  2.5 %     97.5 %
## (Intercept) -0.1379033 0.04797344
## x            4.8650100 5.04883353
system.time(my_boot(dat = data.frame(x, y), mi_stat, R = 4000, ncpus = 1L))
system.time(my_boot(dat = data.frame(x, y), my_stat, R = 4000, ncpus = 1L))
system.time(my_boot(dat = data.frame(x, y), my_stat, R = 4000, ncpus = 2L))
ans
ans0
ans1
str(ans0)
Sys.which("R")
Sys.which("Rscript")
# Data Generating Process (10 x 10,000 matrix)
set.seed(1234)
x <- matrix(rnorm(1e4), nrow=10)
# Find each column's max value
fun2 <- function(x) {
apply(x, 2, max)
}
fun2alt <- function(x) {
# YOUR CODE HERE
#max.col(t(x))
x[cbind(
max.col(t(x)),
1:ncol(x)
)]
}
# Benchmarking
ans_benchmark <= microbenchmark::microbenchmark(
fun2(x),
fun2alt(x), unit = "relative"
)
# Data Generating Process (10 x 10,000 matrix)
set.seed(1234)
x <- matrix(rnorm(1e4), nrow=10)
# Find each column's max value
fun2 <- function(x) {
apply(x, 2, max)
}
fun2alt <- function(x) {
# YOUR CODE HERE
#max.col(t(x))
x[cbind(
max.col(t(x)),
1:ncol(x)
)]
}
# Benchmarking
ans_benchmark <- microbenchmark::microbenchmark(
fun2(x),
fun2alt(x), unit = "relative"
)
plot(ans_benchmark)
View(x)
